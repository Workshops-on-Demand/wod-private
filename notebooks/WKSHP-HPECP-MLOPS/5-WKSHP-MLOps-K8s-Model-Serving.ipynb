{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying end-to-end machine learning workflows with HPE Ezmeral ML Ops - Lab 5\n",
    "## Model serving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Lab workflow:**\n",
    "You have developed and trained a model from a dataset, register the trained model and deployed it in a deployment engine ML Ops application cluster. Now it is time to make predictions (i.e.: _how long my taxi ride take?_) with new input data (i.e.: new data points). \n",
    "The ML Ops deployment engine cluster you just deployed is a set of microservices with a secure RESTful API to serve online predictions. The deployment engine cluster exposes network service endpoints such as a **LoadBalancer and a scalable RESTServer** with token-based authorization that can now be used to serve your model and make predictions using REST API queries from application clients. \n",
    "\n",
    "In this lab:\n",
    "\n",
    "1. You will use kubectl commands in the context of your tenant user account and get the LoadBalancer network service endpoints with token-based authentication of the deployment engine application cluster you have just deployed. \n",
    "\n",
    "2. You will then use **_cURL_** as an HTTP application client for making REST API queries to your model though the API service exposed by the ML Ops deployment engine cluster you have just deployed. \n",
    "\n",
    "\n",
    "**Definitions:**\n",
    "\n",
    "- *Model predictions:* The trained model is deployed to a target _\"deployment engine\"_ ML Ops application virtual cluster environment in the Kubernetes cluster to serve predictions and for answering prediction queries from the trained model you registered.\n",
    "\n",
    "- *Scoring:* Scoring denotes the process of generating predicted values from new input data. The scoring script you specified in the model registry for your trained model is used to load the trained model, read the input data that is being received from the deployment engine REST API endpoint, and make predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1- Initialize the environment**\n",
    "\n",
    "Let's first define the environment variables needed to execute this part of the lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# environment variables\n",
    "#\n",
    "\n",
    "studentId=$(grep hpecp-user $HOME/.kube/config | cut -d= -f2)\n",
    "\n",
    "gateway_host=\"{{ HPEECPGWNAME }}\"\n",
    "Internet_access=\"{{ JPHOSTEXT }}\"\n",
    "\n",
    "sc_secret=\"sc-secret-mlops-students.yaml\" # The secret object for the GitHub VCS information. it is used by the notebook to know how to connect to the VCS.\n",
    "JupyterNotebookApp=\"cr-cluster-mlops-jupyter-notebook.yaml\" # the Jupyter Notebook ML Ops app manifest you will deploy to build your model\n",
    "DeploymentEngineApp=\"cr-cluster-mlops-endpoint-wrapper.yaml\" # the Deployment engine KD App manifest you will deploy to query your model for answers \n",
    "PipelineConfigMap=\"mlops-pipeline-configmap.yaml\" # ConfigMap manifest used to register the trained model version 1 \n",
    "#\n",
    "clusterName=\"mlops-inference-server-${studentId}\"\n",
    "#\n",
    "# Model registry information\n",
    "#\n",
    "TrainingModel=\"mlops-model-${studentId}\"\n",
    "modelVersion=\"1\"\n",
    "#\n",
    "echo \"Your studentId is: \"$studentId "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2- Serving queries through the Load Balancer service of the deployment engine cluster**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the service endpoint and the Authentication token of the Load Balancer of the deployment engine cluster:\n",
    "To get a report on all services related to a specific virtual cluster, you can use a form of **kubectl describe** that matches against a value of the **kubedirector.hpe.com/kdcluster=YourClusterApplicationName,kubedirector.hpe.com/role=LoadBalancer** label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Getting the Model Serving access point from the haproxy service of the LoadBalancer (role: LoadBalancer, internal port: 32700):\n",
    "#\n",
    "LoadBalancerURL=$(kubectl describe service -l kubedirector.hpe.com/kdcluster=${clusterName},kubedirector.hpe.com/role=LoadBalancer | grep gateway/32700 | awk '{print $2}')\n",
    "LoadBalancerPort=$(echo $LoadBalancerURL | cut -d':' -f 2) # extract the gateway re-mapped port value.\n",
    "LoadBalancer_endpoint=\"https://$gateway_host:$LoadBalancerPort\"\n",
    "echo \"The Model Serving LoadBalancer service endpoint re-mapped port is: \"$LoadBalancerPort\n",
    "echo \"Your Model Serving LoadBalancer service endpoint is: \"$LoadBalancer_endpoint\n",
    "#echo \"The LoadBalancer service endpoint URL is: \"https://$Internet_access:$RESTServerPort\n",
    "#\n",
    "# Getting the auth-token:\n",
    "#\n",
    "LoadBalancerAuthToken=$(kubectl describe service -l kubedirector.hpe.com/kdcluster=${clusterName},kubedirector.hpe.com/role=LoadBalancer | grep kd-auth-token  | awk '{print $2}' | tr -d '\\r')\n",
    "echo \"The Model Serving Load Balancer service authentication token is: \"$LoadBalancerAuthToken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3- Making predictions on new data**\n",
    "To make a prediction, you create an authenticated \"POST\" REST API call and send it to the prediction service endpoint (that is, the deployment engine REST API network service endpoint). The REST API call is formulated as follows:  \n",
    "https://loadbalancer_endpoint/registeredModel/modelVersion/predict\n",
    "\n",
    "The query below is used to predict how long a taxi ride in NY City with attributes listed below will take based on:\n",
    "* pickup location: West 23rd street\n",
    "* dropoff location: Centre Market place \n",
    "* on a weekday \n",
    "* at 09:00 am \n",
    "* in February\n",
    "\n",
    ">Note: _It may take a few seconds for the prediction service to generate the prediction and send the result of the REST API call back to the cURL HTTP application client._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curl --location -k -s --request POST \"${LoadBalancer_endpoint}/${TrainingModel}/${modelVersion}/predict\" \\\n",
    "--header \"X-Auth-Token: ${LoadBalancerAuthToken}\" \\\n",
    "--header 'Content-Type: application/json' \\\n",
    "--data-raw '{\n",
    "    \"use_scoring\": true,\n",
    "    \"scoring_args\": {\n",
    "        \"work\": 0,\n",
    "        \"start_latitude\": 40.57689727,\n",
    "        \"start_longitude\": -73.99047356,\n",
    "        \"end_latitude\": 40.72058154,\n",
    "        \"end_longitude\": -73.99740673,\n",
    "        \"distance\": 8,\n",
    "        \"weekday\": 1,\n",
    "        \"hour\": 9,\n",
    "        \"month_1\": 0,\n",
    "        \"month_2\": 1,\n",
    "        \"month_3\": 0,\n",
    "        \"month_4\": 0,\n",
    "        \"month_5\": 0,\n",
    "        \"month_6\": 0\n",
    "    }\n",
    "}' | python -m json.tool | grep output | cut -d'\\' -f 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new data that you provide as input have the same columns (features) that were used to train the model, minus the outcome column. \n",
    "> Fields description:\n",
    "> * work is a boolean for work hours (1 if the ride occurs Mon-Fri 8am-5pm, 0 otherwise)\n",
    "> * start_latitude is the pickup location latitude\n",
    "> * start_longitude is the pickup location longitude\n",
    "> * end_latitude is the dropoff location latitude\n",
    "> * end_longitude is the dropoff location longitude\n",
    "> * distance is the trip distance in miles\n",
    "> * weekday is a boolean for weekday (1 if the ride occurs on Mon-Fri, 0 otherwise)\n",
    "> * hour is the hour of day (0 to 23)\n",
    "> * month_1 is a boolean if the ride is is in January (1 if true, 0 otherwise)\n",
    "> * month_2 is a boolean if the ride is is in February (1 if true, 0 otherwise)\n",
    "> * month_3 is a boolean if the ride is is in March (1 if true, 0 otherwise)\n",
    "> * month_4 is a boolean if the ride is is in April (1 if true, 0 otherwise)\n",
    "> * month_5 is a boolean if the ride is is in May (1 if true, 0 otherwise)\n",
    "> * month_6 is a boolean if the ride is is in June (1 if true, 0 otherwise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4- Time to go through some cleanup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kubectl delete -f $sc_secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kubectl delete -f $DeploymentEngineApp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kubectl delete -f $PipelineConfigMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kubectl delete -f $JupyterNotebookApp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab, we have shown you how you can make prediction queries, using REST API calls, to a target deployment engine ML Ops application virtual cluster environment that serves your model.\n",
    "\n",
    "* [Conclusion](6-Conclusion.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
